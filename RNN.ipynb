{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "731yxJj9sbTX",
        "colab_type": "code",
        "outputId": "4a867738-631a-4eb8-df86-29b5e4288771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "\n",
        "\n",
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        " \n",
        "import pdb\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "file = unidecode.unidecode(open('./text_files/lotr.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-13 20:25:59--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 34.205.95.128, 52.45.119.166, 52.2.48.133, ...\n",
            "Connecting to piazza.com (piazza.com)|34.205.95.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2019-10-13 20:25:59--  https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)... 13.249.26.154, 13.249.26.66, 13.249.26.57, ...\n",
            "Connecting to d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)|13.249.26.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "./text_files.tar.gz 100%[===================>]   1.46M  4.38MB/s    in 0.3s    \n",
            "\n",
            "2019-10-13 20:26:00 (4.38 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n",
            "file_len = 2579888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8bT2eh0s5D1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chunk_len = 200\n",
        " \n",
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNO6mMUss89P",
        "colab_type": "code",
        "outputId": "46a9839b-808e-4c80-c78b-8ec85b35f63a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "  return Variable(tensor)\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9DgQwPFXVyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##the encoder\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    \n",
        "    self.embedding = nn.Embedding(input_size,hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, input_char, hidden):\n",
        "    #pdb.set_trace()\n",
        "    embedded = self.embedding(input_char).view(1,1,-1)\n",
        "    output = embedded\n",
        "    output,hidden = self.gru(output,hidden)\n",
        "    return output,hidden\n",
        "    \n",
        "    \n",
        "\n",
        "  def init_hidden(self):\n",
        "    return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
        "  \n",
        "##the decoder\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = nn.functional.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWUhqfq8Xd3i",
        "colab_type": "code",
        "outputId": "abab3b38-4dab-4aa2-ad03-9496fc2781ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def random_training_set():    \n",
        "  chunk = random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target\n",
        "\n",
        "training_set=random_training_set()\n",
        "decoder=DecoderRNN(chunk_len,chunk_len)\n",
        "encoder=RNN(chunk_len,chunk_len,chunk_len)\n",
        "inp,target=random_training_set()\n",
        "\n",
        "learning_rate=0.0001\n",
        "\n",
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "Max_length=target.size(0)\n",
        "\n",
        "def train(inp, target,decoder,encoder,decoder_optimizer,encoder_optimizer,criterion,max_length=Max_length):\n",
        "  \n",
        "  #encoder_hidden = \n",
        "  ## initialize hidden layers, set up gradient and loss \n",
        "    # your code here\n",
        "  ## /\n",
        "  decoder_optimizer.zero_grad()\n",
        "  encoder_optimizer.zero_grad()\n",
        "  \n",
        "  input_length=inp.size(0)\n",
        "  target_length=target.size(0)\n",
        "  print(encoder.hidden_size)\n",
        "  print(max_length)\n",
        "  encoder_outputs=torch.zeros(max_length,encoder.hidden_size,device=device)\n",
        "  \n",
        "  hidden_e = encoder.init_hidden()\n",
        "  \n",
        "  loss = 0\n",
        "  \n",
        "  for i in range(input_length):\n",
        "    #pdb.set_trace()\n",
        "    encoder_output,encoder_hidden=encoder(inp[i],hidden_e)\n",
        "    encoder_outputs[i]=encoder_output[0,0]\n",
        "  pdb.set_trace()\n",
        "  decoder_input = torch.tensor([[0]],device=device)\n",
        "  \n",
        "  decoder_hidden=encoder_hidden\n",
        "  teacher_forcing_ratio=0.5\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "      # Teacher forcing: Feed the target as the next input\n",
        "      for di in range(target_length):\n",
        "          pdb.set_trace()\n",
        "          decoder_output, decoder_hidden= decoder(\n",
        "              decoder_input, decoder_hidden)\n",
        "          \n",
        "          loss += criterion(decoder_output, target[di])\n",
        "          decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "  else:\n",
        "      # Without teacher forcing: use its own predictions as the next input\n",
        "      for di in range(target_length):\n",
        "          print(di)\n",
        "          decoder_output, decoder_hidden= decoder(\n",
        "              decoder_input, decoder_hidden, encoder_outputs)\n",
        "          \n",
        "          topv, topi = decoder_output.topk(1)\n",
        "          decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "          loss += criterion(decoder_output, target_tensor[di])\n",
        "          if decoder_input.item() == EOS_token:\n",
        "              break\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "\n",
        "  return loss.item() / target_length\n",
        "  \n",
        " \n",
        "  \n",
        "  # more stuff here...\n",
        "\n",
        "train(inp,target,decoder,encoder,decoder_optimizer,encoder_optimizer,criterion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "> <ipython-input-22-b6e810448c01>(47)train()\n",
            "-> decoder_input = torch.tensor([[0]],device=device)\n",
            "(Pdb) n\n",
            "> <ipython-input-22-b6e810448c01>(49)train()\n",
            "-> decoder_hidden=encoder_hidden\n",
            "(Pdb) n\n",
            "> <ipython-input-22-b6e810448c01>(50)train()\n",
            "-> teacher_forcing_ratio=0.5\n",
            "(Pdb) n\n",
            "> <ipython-input-22-b6e810448c01>(51)train()\n",
            "-> use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
            "(Pdb) n\n",
            "> <ipython-input-22-b6e810448c01>(53)train()\n",
            "-> if use_teacher_forcing:\n",
            "(Pdb) n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGnYGQ6SntUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target.size(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}